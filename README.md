 🧠 NLP Lab

A personal playground for **Natural Language Processing** — where I experiment, learn, and build everything from foundational models to cutting-edge research prototypes.

---

## 🌟 About This Lab
My journey into NLP began after reading [_Attention Is All You Need_](https://arxiv.org/abs/1706.03762).  
Seeing how **transformers** reshaped the field — and how quickly NLP was evolving — pushed me to dive deeper.

Since then, I've explored:
- ⚙️ **Implementations** of core NLP models (transformers, RNNs, etc.)
- 🧩 **Embedding** techniques, tokenization strategies, and sequence modeling
- 🚀 **Applications** of models to real-world problems

---

## 🔍 Current Focus: Theory of Mind in LLMs
Recently, I've been researching how large language models handle **Theory of Mind (ToM)**:
> Can machines reason about beliefs, knowledge, and intentions like humans do?

This repository brings together:
- Coursework projects
- Independent experiments
- Research prototypes for probing LLM cognitive abilities

---

## 📂 Contents
- **Foundations** → Early NLP exercises and conceptual work  
- **Model Implementations** → From scratch & library-based architectures  
- **Research Experiments** → Probing ToM and other cognitive behaviors in LLMs  

---

## 🚀 Future Plans
- Extend ToM experiments with new prompt engineering techniques
- Explore multi-turn conversational reasoning benchmarks
- Integrate ToM probing into fine-tuning workflows

---
